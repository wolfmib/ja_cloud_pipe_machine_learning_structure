{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mCat\u001b[m\u001b[m/ \u001b[1m\u001b[34mDog\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls data_one/PetImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### random fill data to train and validation folder with 80% ratio ######## \n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from random import sample\n",
    "\n",
    "\n",
    "\n",
    "# Define paths\n",
    "base_dir = './data_one/PetImages'  # Replace with the path to your PetImages folder\n",
    "classes = ['Cat', 'Dog']\n",
    "train_dir = os.path.join(\"model_one\", 'train')\n",
    "validation_dir = os.path.join(\"model_one\", 'validation')\n",
    "\n",
    "# Split ratio\n",
    "train_ratio = 0.8\n",
    "\n",
    "# Make new dirs\n",
    "for cl in classes:\n",
    "    os.makedirs(os.path.join(train_dir, cl), exist_ok=True)\n",
    "    os.makedirs(os.path.join(validation_dir, cl), exist_ok=True)\n",
    "\n",
    "# Move files\n",
    "for cl in classes:\n",
    "    # Source dir\n",
    "    src_dir = os.path.join(base_dir, cl)\n",
    "    all_files = os.listdir(src_dir)\n",
    "    \n",
    "    # Shuffle and split files\n",
    "    train_files = sample(all_files, int(len(all_files) * train_ratio))\n",
    "    validation_files = list(set(all_files) - set(train_files))\n",
    "    \n",
    "    # Move to train_dir\n",
    "    for file_name in train_files:\n",
    "        shutil.move(os.path.join(src_dir, file_name), os.path.join(train_dir, cl))\n",
    "    \n",
    "    # Move to validation_dir\n",
    "    for file_name in validation_files:\n",
    "        shutil.move(os.path.join(src_dir, file_name), os.path.join(validation_dir, cl))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19966 images belonging to 2 classes.\n",
      "Found 4993 images belonging to 2 classes.\n",
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "16711680/16705208 [==============================] - 4s 0us/step\n",
      "Epoch 1/15\n",
      "100/100 [==============================] - 97s 966ms/step - loss: 0.7516 - accuracy: 0.5030 - val_loss: 0.6935 - val_accuracy: 0.5060\n",
      "Epoch 2/15\n",
      "100/100 [==============================] - 99s 989ms/step - loss: 0.7124 - accuracy: 0.4955 - val_loss: 0.6960 - val_accuracy: 0.5030\n",
      "Epoch 3/15\n",
      "100/100 [==============================] - 101s 1s/step - loss: 0.7020 - accuracy: 0.5045 - val_loss: 0.6972 - val_accuracy: 0.4960\n",
      "Epoch 4/15\n",
      " 69/100 [===================>..........] - ETA: 23s - loss: 0.6935 - accuracy: 0.5065"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Train !! ###\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Set up image directories\n",
    "train_dir = './model_one/train'\n",
    "validation_dir = './model_one/validation'\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Sigmoid because we have two classes\n",
    "])\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "\n",
    "# Image augmentation\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=40, width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(150, 150), batch_size=20, class_mode='binary')\n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator = test_datagen.flow_from_directory(validation_dir, target_size=(150, 150), batch_size=20, class_mode='binary')\n",
    "\n",
    "# Load the base model, pre-trained on ImageNet\n",
    "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "\n",
    "# Freeze the convolutional base\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create a new model on top\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "## Hyper parameter\n",
    "steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
    "validation_steps = validation_generator.samples // validation_generator.batch_size\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=15, validation_data=validation_generator, validation_steps=validation_steps)\n",
    "\n",
    "# Save the model\n",
    "model.save('cats_and_dogs_classifier.h5')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 34, 34, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 36992)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               18940416  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 19,034,177\n",
      "Trainable params: 19,034,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Input shape: (None, 150, 150, 3)\n",
      "Output shape: (None, 1)\n"
     ]
    }
   ],
   "source": [
    "## loaidng information\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model('cats_and_dogs_classifier.h5')\n",
    "\n",
    "\n",
    "# Print the model architecture\n",
    "model.summary()\n",
    "\n",
    "# Get input and output of the model\n",
    "print(\"Input shape:\", model.input_shape)\n",
    "print(\"Output shape:\", model.output_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19966 images belonging to 2 classes.\n",
      "{'Cat': 0, 'Dog': 1}\n"
     ]
    }
   ],
   "source": [
    "## GET Class\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Assuming you used ImageDataGenerator for training\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'model_one/train',  # path to the directory of training data\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary')\n",
    "\n",
    "# Print class indices\n",
    "print(train_generator.class_indices)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediciotn is [[0.6375128]]\n",
      "The image with path temp_load/test_chat.jpg is a Dog.\n"
     ]
    }
   ],
   "source": [
    "## Loading test\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('cats_and_dogs_classifier.h5')\n",
    "\n",
    "# Define the path to the new image\n",
    "image_path = 'temp_load/test_chat.jpg'\n",
    "\n",
    "# Load the image\n",
    "img = image.load_img(image_path, target_size=(150, 150))\n",
    "\n",
    "# Preprocess the image\n",
    "img_tensor = image.img_to_array(img)  # Convert the image to a numpy array\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)  # Add batch dimension\n",
    "img_tensor /= 255.  # Model expects input in the range [0, 1]\n",
    "\n",
    "# Predict the class of the image\n",
    "prediction = model.predict(img_tensor)\n",
    "\n",
    "# Interpret the output\n",
    "# Assuming the output of the model is binary:\n",
    "# '0' is for 'Cat' and '1' is for 'Dog'\n",
    "print(f\"prediciotn is {prediction}\")\n",
    "if prediction < 0.5:\n",
    "    print(f\"The image with path {image_path} is a Cat.\")\n",
    "else:\n",
    "    print(f\"The image with path {image_path} is a Dog.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breaking Down image loaing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape >> (150, 150, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "189.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step one: 150, 150, 3\n",
    "# Define the path to the new image\n",
    "image_path = 'temp_load/test_chat.jpg'\n",
    "\n",
    "# Load the image\n",
    "img = image.load_img(image_path, target_size=(150, 150))\n",
    "img_tensor = image.img_to_array(img)\n",
    "print(f\"Shape >> {img_tensor.shape}\")\n",
    "\n",
    "img_tensor[149][149][2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 150, 150, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step Two: Add Batch example\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "img_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.9882353 , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 0.99215686],\n",
       "         [1.        , 1.        , 0.99215686],\n",
       "         ...,\n",
       "         [0.73333335, 0.6039216 , 0.5372549 ],\n",
       "         [0.79607844, 0.70980394, 0.65882355],\n",
       "         [1.        , 0.9882353 , 0.96862745]],\n",
       "\n",
       "        [[0.9882353 , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 0.99215686],\n",
       "         [1.        , 1.        , 0.99215686],\n",
       "         ...,\n",
       "         [0.7607843 , 0.6313726 , 0.5647059 ],\n",
       "         [0.7882353 , 0.69411767, 0.64705884],\n",
       "         [1.        , 0.9764706 , 0.9647059 ]],\n",
       "\n",
       "        [[0.9882353 , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 0.99215686],\n",
       "         [1.        , 1.        , 0.99215686],\n",
       "         ...,\n",
       "         [0.7607843 , 0.6313726 , 0.5568628 ],\n",
       "         [0.8156863 , 0.72156864, 0.6745098 ],\n",
       "         [1.        , 0.9843137 , 0.9764706 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.80784315, 0.76862746, 0.72156864],\n",
       "         [0.7529412 , 0.7019608 , 0.6392157 ],\n",
       "         [0.78039217, 0.7176471 , 0.654902  ],\n",
       "         ...,\n",
       "         [0.72156864, 0.68235296, 0.6431373 ],\n",
       "         [0.6666667 , 0.6313726 , 0.59607846],\n",
       "         [0.77254903, 0.7607843 , 0.7411765 ]],\n",
       "\n",
       "        [[0.84313726, 0.8117647 , 0.76862746],\n",
       "         [0.72156864, 0.6745098 , 0.61960787],\n",
       "         [0.73333335, 0.68235296, 0.61960787],\n",
       "         ...,\n",
       "         [0.67058825, 0.6313726 , 0.5921569 ],\n",
       "         [0.6156863 , 0.5803922 , 0.5529412 ],\n",
       "         [0.7490196 , 0.7294118 , 0.7137255 ]],\n",
       "\n",
       "        [[0.85490197, 0.8235294 , 0.78039217],\n",
       "         [0.81960785, 0.77254903, 0.7254902 ],\n",
       "         [0.8039216 , 0.7529412 , 0.6901961 ],\n",
       "         ...,\n",
       "         [0.68235296, 0.6431373 , 0.60784316],\n",
       "         [0.6509804 , 0.60784316, 0.58431375],\n",
       "         [0.7764706 , 0.75686276, 0.7411765 ]]]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Step scal [0,1]\n",
    "img_tensor /= 255. \n",
    "img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.7193088531494141, 0.6946874856948853, 0.6871427893638611, 0.6872152090072632, 0.6900128722190857, 0.6850082874298096, 0.6849346160888672, 0.6863163113594055, 0.6850281357765198, 0.677954912185669, 0.6882190704345703, 0.6764642000198364, 0.674538254737854, 0.6645799279212952, 0.6728416085243225], 'accuracy': [0.5270000100135803, 0.49549999833106995, 0.5605000257492065, 0.559499979019165, 0.546500027179718, 0.5720040202140808, 0.5513595342636108, 0.5599194169044495, 0.5684999823570251, 0.5755000114440918, 0.5629405975341797, 0.5964999794960022, 0.597000002861023, 0.6110000014305115, 0.5954999923706055], 'val_loss': [0.7069425582885742, 0.686040997505188, 0.6783363819122314, 0.6833188533782959, 0.6895650029182434, 0.6856113076210022, 0.6807612776756287, 0.6834836602210999, 0.6620160341262817, 0.6566139459609985, 0.6546926498413086, 0.6858153939247131, 0.6606965065002441, 0.6524175405502319, 0.6486132144927979], 'val_accuracy': [0.5009999871253967, 0.5709999799728394, 0.597000002861023, 0.5659999847412109, 0.5249999761581421, 0.5440000295639038, 0.550000011920929, 0.5609999895095825, 0.6179999709129333, 0.6129999756813049, 0.6539999842643738, 0.5740000009536743, 0.5950000286102295, 0.6100000143051147, 0.6430000066757202]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# Write\n",
    "\"\"\"\n",
    "# Convert the history.history dict to a JSON file\n",
    "with open('model_history.json', 'w') as f:\n",
    "    json.dump(history.history, f)\n",
    "\"\"\"\n",
    "\n",
    "## Load\n",
    "# Load history from JSON\n",
    "with open('model_history.json', 'r') as f:\n",
    "    loaded_history = json.load(f)\n",
    "\n",
    "print(loaded_history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Matplotlib requires numpy>=1.20; you have 1.18.5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m##\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Plot training & validation accuracy values\u001b[39;00m\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/Documents/ja_interview_entretien/ja_git/myenv/lib/python3.8/site-packages/matplotlib/__init__.py:227\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m parse_version(module\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m parse_version(minver):\n\u001b[1;32m    223\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatplotlib requires \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mminver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    224\u001b[0m                               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 227\u001b[0m \u001b[43m_check_versions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;66;03m# The decorator ensures this always returns the same handler (and it is only\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# attached once).\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache()\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ensure_handler\u001b[39m():\n",
      "File \u001b[0;32m~/Documents/ja_interview_entretien/ja_git/myenv/lib/python3.8/site-packages/matplotlib/__init__.py:223\u001b[0m, in \u001b[0;36m_check_versions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    221\u001b[0m module \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(modname)\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parse_version(module\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m parse_version(minver):\n\u001b[0;32m--> 223\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatplotlib requires \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mminver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    224\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: Matplotlib requires numpy>=1.20; you have 1.18.5"
     ]
    }
   ],
   "source": [
    "##\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_env)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
